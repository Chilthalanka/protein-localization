experiment_name: ''

num_epochs: 5000
batch_size: 2
optimizer_parameters:
  lr: 1.0e-4
log_iterations: 1
checkpoint: 'runs/SelfAttention2Layer__03-10_10-32-16'

# Paths to Data
train_embeddings: 'data/embeddings/train.h5'
val_embeddings: 'data/embeddings/val.h5'
test_embeddings: 'data/embeddings/test.h5'
train_remapping: 'data/embeddings/train_remapped.fasta'
val_remapping: 'data/embeddings/val_remapped.fasta'
test_remapping: 'data/embeddings/test_remapped.fasta'

# Model parameters
model_type: 'SelfAttention2Layer' # the actual name of the class of the model that should be used
model_parameters:
  dropout: 0.25
  attention_dropout: 0.25
  n_heads: 8
