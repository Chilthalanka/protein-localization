experiment_name: '2layer_128'

num_epochs: 10000
batch_size: 64
log_iterations: 2
solubility_loss: 0
optimizer_parameters:
  lr: 5.0e-5
#checkpoint: 'runs/max_avg_dropout05_27-09_08-49-02'

# Paths to Data
train_embeddings: '/mnt/project/bio_embeddings/runs/hannes/embed_train/embeddings/bert_embeddings/embeddings_file.h5'
train_remapping: '/mnt/project/bio_embeddings/runs/hannes/embed_train/embeddings/remapped_sequences_file.fasta'
val_embeddings: '/mnt/project/bio_embeddings/runs/hannes/embed_val/embeddings/bert_embeddings/embeddings_file.h5'
val_remapping: '/mnt/project/bio_embeddings/runs/hannes/embed_val/embeddings/remapped_sequences_file.fasta'
test_embeddings: '/mnt/project/bio_embeddings/runs/hannes/embed_test/embeddings/bert_embeddings/embeddings_file.h5'
test_remapping: '/mnt/project/bio_embeddings/runs/hannes/embed_test/embeddings/remapped_sequences_file.fasta'

# Model parameters
model_type: 'LSTMConv'
model_parameters:
  output_dim: 11
  lstm_hidden_dim: 128
  n_layers: 2
  kernel_size: 9
  dropout: 0.2
